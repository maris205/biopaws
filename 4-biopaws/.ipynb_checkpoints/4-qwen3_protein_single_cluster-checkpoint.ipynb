{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d79e817-6ae3-4eae-80c4-ed3453fdea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# # æ‰“å°ç¯å¢ƒå˜é‡ä»¥ç¡®è®¤è®¾ç½®æˆåŠŸ\n",
    "# print(os.environ.get('HF_ENDPOINT'))\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ec97c3-d930-4755-942b-998a4db4cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce11eec2-01f3-4a26-a71b-b5f15e7ef5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. é…ç½® API  https://bailian.console.aliyun.com/\n",
    "# ==========================================\n",
    "API_KEY = \"sk-\"  # æ³¨æ„ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¯·å‹¿ç¡¬ç¼–ç ï¼Œå»ºè®®ä½¿ç”¨ os.getenv\n",
    "MODEL_ID = \"qwen3-max\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a169ef-21ec-4b0c-a767-fdfcdeec1973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'biomap-research/solubility_prediction' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BioMap Solubility dataset...\n",
      "Cluster Batch Prepared: 30 sequences.\n",
      "(Pos: 15, Neg: 15)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ==========================================\n",
    "# 1. æ•°æ®å‡†å¤‡ï¼šæ„å»ºèšç±»ç”¨çš„ Batch\n",
    "# ==========================================\n",
    "print(\"Loading BioMap Solubility dataset...\")\n",
    "try:\n",
    "    dataset = load_dataset(\"biomap-research/solubility_prediction\", trust_remote_code=True)\n",
    "    train_ds = dataset['train']\n",
    "    \n",
    "    # ç­›é€‰å‡½æ•°ï¼šåªè¦é•¿åº¦ < 250 çš„ï¼ˆä¸ºäº†è®©ä¸€æ¬¡ Prompt èƒ½å¡è¿›æ›´å¤šæ¡æ•°æ®è¿›è¡Œå¯¹æ¯”ï¼‰\n",
    "    def get_candidates(ds, label_val, limit, max_len=250):\n",
    "        candidates = []\n",
    "        # éå†å‰ 10000 æ¡å¯»æ‰¾ç¬¦åˆæ¡ä»¶çš„\n",
    "        for i in range(min(len(ds), 10000)):\n",
    "            item = ds[i]\n",
    "            if item['label'] == label_val and len(item['seq']) <= max_len:\n",
    "                candidates.append(item)\n",
    "                if len(candidates) >= limit:\n",
    "                    break\n",
    "        return candidates\n",
    "\n",
    "    # å„é‡‡ 15 æ¡ (æ€»å…± 30 æ¡ï¼Œè¿™æ˜¯ä¸€ä¸ªé€‚åˆåš In-Context Clustering çš„å¤§å°)\n",
    "    batch_size_per_class = 15\n",
    "    data_pos = get_candidates(train_ds, 1, batch_size_per_class)\n",
    "    data_neg = get_candidates(train_ds, 0, batch_size_per_class)\n",
    "    \n",
    "    # åˆå¹¶å¹¶æ‰“ä¹±\n",
    "    cluster_batch = data_pos + data_neg\n",
    "    random.seed(42) # å›ºå®šç§å­æ–¹ä¾¿å¤ç°\n",
    "    random.shuffle(cluster_batch)\n",
    "    \n",
    "    print(f\"Cluster Batch Prepared: {len(cluster_batch)} sequences.\")\n",
    "    print(f\"(Pos: {len(data_pos)}, Neg: {len(data_neg)})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 2. æ„å»º Prompt ç”¨çš„ JSON\n",
    "# ==========================================\n",
    "prompt_data_list = []\n",
    "id_to_ground_truth = {}\n",
    "\n",
    "for idx, item in enumerate(cluster_batch, 1):\n",
    "    prompt_data_list.append({\n",
    "        \"id\": idx,\n",
    "        \"sequence\": item['seq']\n",
    "    })\n",
    "    id_to_ground_truth[idx] = item['label']\n",
    "\n",
    "# æ‰“å°å‡ºæ•°æ®çœ‹çœ‹ (å¤åˆ¶åˆ° User Prompt)\n",
    "# print(json.dumps(prompt_data_list, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56575ef6-7c2a-4b34-832e-983f4130410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. æ„å»º Prompt (ç”Ÿç‰©ç‰©ç†èšç±»ç‰ˆ)\n",
    "# ==========================================\n",
    "\n",
    "# System Prompt: è®¾å®šä¸ºâ€œè›‹ç™½è´¨ç”Ÿç‰©ç‰©ç†å­¦å®¶â€ï¼Œå¹¶ç»™å‡ºèšç±»æ ‡å‡†\n",
    "system_prompt = \"\"\"You are an expert in Protein Biophysics and Sequence Clustering.\n",
    "\n",
    "1. The Task:\n",
    "You are provided with a batch of protein sequences. This batch is a mixture of two distinct classes based on solubility properties.\n",
    "Your goal is to separate them into two clusters based on their amino acid composition and physicochemical patterns.\n",
    "\n",
    "2. The Two Clusters:\n",
    "* **Cluster 1 (Soluble-like)**:\n",
    "   - High proportion of charged/polar residues (D, E, K, R, S, T).\n",
    "   - Low hydrophobicity.\n",
    "   - Structurally looks like stable, globular proteins.\n",
    "* **Cluster 0 (Insoluble/Aggregation-prone)**:\n",
    "   - High proportion of hydrophobic residues (L, I, V, F, W, Y) exposed or in patterns.\n",
    "   - Low complexity or repetitive regions.\n",
    "   - Structurally looks prone to precipitation or inclusion body formation.\n",
    "\n",
    "3. Output Requirements:\n",
    "* Analyze the RELATIVE differences between sequences in the batch.\n",
    "* Perform a binary clustering.\n",
    "* Return a RAW JSON object: `[{\"id\": 1, \"prediction\": 1}, {\"id\": 2, \"prediction\": 0}, ...]`\n",
    "\"\"\"\n",
    "\n",
    "# User Prompt: å¼ºè°ƒâ€œå¯¹æ¯”åˆ†æâ€ (Comparative Analysis)\n",
    "user_prompt = f\"\"\"Here is the batch of {len(prompt_data_list)} protein sequences.\n",
    "\n",
    "**Instruction:**\n",
    "Perform a comparative analysis of these sequences.\n",
    "Group them into **Soluble (1)** and **Insoluble (0)** based on the physicochemical criteria defined above.\n",
    "\n",
    "**Data Batch:**\n",
    "{json.dumps(prompt_data_list, indent=2)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc5e7df1-0b13-4f49-8e23-2f40d236a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Calling Volcengine Model: qwen3-max...\n",
      "Response received.\n",
      "Response snippet: ```json\n",
      "[\n",
      "  {\"id\": 1, \"prediction\": 0},\n",
      "  {\"id\": 2, \"prediction\": 1},\n",
      "  {\"id\": 3, \"prediction\": 1},\n",
      "  {\"id\": 4, \"prediction\": 1},\n",
      "  {\"id\": 5, \"prediction\": 1},\n",
      "  {\"id\": 6, \"prediction\": 1},\n",
      "  {\"id\": 7...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. è°ƒç”¨ Volcengine API\n",
    "# ==========================================\n",
    "print(\"-\" * 30)\n",
    "print(f\"Calling Volcengine Model: {MODEL_ID}...\")\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_ID,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.1, # ä½æ¸©ä»¥ä¿è¯è¾“å‡ºæ ¼å¼ç¨³å®š\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    \n",
    "    full_content = response.choices[0].message.content.strip()\n",
    "    print(\"Response received.\")\n",
    "    # æ‰“å°å‰200ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•\n",
    "    print(f\"Response snippet: {full_content[:200]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"API Call Failed: {e}\")\n",
    "    full_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2086d156-fc5a-42ac-8d63-38a42c657cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Parsing Model Response...\n",
      "âœ… Successfully matched 30 sequences.\n",
      "\n",
      "âš ï¸ Detected Label Reversal! (Raw Accuracy: 43.33%)\n",
      ">>> The model successfully clustered the data but swapped the label meanings.\n",
      ">>> Auto-correcting predictions (0 -> 1, 1 -> 0)...\n",
      "\n",
      "==============================\n",
      "ğŸ† FINAL ACCURACY: 56.67%\n",
      "==============================\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Insoluble (0)       0.54      0.87      0.67        15\n",
      "  Soluble (1)       0.67      0.27      0.38        15\n",
      "\n",
      "     accuracy                           0.57        30\n",
      "    macro avg       0.60      0.57      0.52        30\n",
      " weighted avg       0.60      0.57      0.52        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  2]\n",
      " [11  4]]\n",
      "\n",
      "[Matrix Interpretation]\n",
      "True Insoluble (Correct): 13\n",
      "True Soluble   (Correct): 4\n",
      "False Positives (Noise classified as Signal): 2\n",
      "False Negatives (Signal classified as Noise): 11\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ==========================================\n",
    "# 5. ç»“æœè§£æä¸æ™ºèƒ½è¯„ä¼°æ¨¡å—\n",
    "# ==========================================\n",
    "\n",
    "def parse_llm_json(text):\n",
    "    \"\"\"\n",
    "    é²æ£’çš„ JSON è§£æå™¨ï¼š\n",
    "    1. å°è¯•æå– Markdown ä»£ç å—ä¸­çš„ JSON\n",
    "    2. å°è¯•æå– [] åŒ…è£¹çš„æ•°ç»„\n",
    "    3. å°è¯•ç›´æ¥è§£æ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # æ¨¡å¼1: ä¹Ÿå°±æ˜¯ ```json [...] ```\n",
    "        code_block = re.search(r\"```(?:json)?\\s*(\\[.*?\\])\\s*```\", text, re.DOTALL)\n",
    "        if code_block:\n",
    "            return json.loads(code_block.group(1))\n",
    "        \n",
    "        # æ¨¡å¼2: ç›´æ¥æ‰¾æ–¹æ‹¬å· [...]\n",
    "        match = re.search(r\"\\[.*\\]\", text, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group(0))\n",
    "            \n",
    "        # æ¨¡å¼3: çº¯æ–‡æœ¬å°è¯•\n",
    "        return json.loads(text)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ JSON Parsing Failed: {e}\")\n",
    "        print(f\"Raw Content Snippet: {text[:200]}...\")\n",
    "        return []\n",
    "\n",
    "# 1. è§£ææ¨¡å‹è¾“å‡º\n",
    "print(\"-\" * 50)\n",
    "print(\"Parsing Model Response...\")\n",
    "predictions_list = parse_llm_json(full_content)\n",
    "\n",
    "# 2. å¯¹é½çœŸå€¼ (Ground Truth)\n",
    "y_true = []\n",
    "y_pred_raw = []\n",
    "valid_count = 0\n",
    "\n",
    "if not predictions_list:\n",
    "    print(\"âŒ No valid predictions parsed.\")\n",
    "else:\n",
    "    for item in predictions_list:\n",
    "        p_id = item.get('id')\n",
    "        p_val = item.get('prediction')\n",
    "        \n",
    "        # ç¡®ä¿ ID å­˜åœ¨äºæˆ‘ä»¬çš„è®°å½•ä¸­ï¼Œä¸”é¢„æµ‹å€¼æ˜¯æœ‰æ•ˆçš„ 0 æˆ– 1\n",
    "        if p_id in id_to_ground_truth and p_val in [0, 1]:\n",
    "            y_true.append(id_to_ground_truth[p_id])\n",
    "            y_pred_raw.append(int(p_val))\n",
    "            valid_count += 1\n",
    "        else:\n",
    "            # å¯é€‰ï¼šæ‰“å°æ— æ•ˆçš„é¢„æµ‹æ–¹ä¾¿è°ƒè¯•\n",
    "            # print(f\"Skipping invalid item: {item}\")\n",
    "            pass\n",
    "\n",
    "    print(f\"âœ… Successfully matched {valid_count} sequences.\")\n",
    "\n",
    "    if valid_count > 0:\n",
    "        # ---------------------------------------------------------\n",
    "        # 3. æ ¸å¿ƒé€»è¾‘ï¼šè‡ªåŠ¨åè½¬æ£€æµ‹ (Label Flipping Detection)\n",
    "        # ---------------------------------------------------------\n",
    "        # å¯¹äºèšç±»ä»»åŠ¡ï¼Œæ¨¡å‹å¯èƒ½åˆ†å¯¹äº†ç»„ï¼Œä½†æ˜¯è´´åäº†æ ‡ç­¾ã€‚\n",
    "        # å¦‚æœå‡†ç¡®ç‡ < 50%ï¼Œæˆ‘ä»¬å‡è®¾å‘ç”Ÿäº†è¿™ç§æƒ…å†µå¹¶è¿›è¡Œçº æ­£ã€‚\n",
    "        \n",
    "        acc_raw = accuracy_score(y_true, y_pred_raw)\n",
    "        \n",
    "        final_y_pred = y_pred_raw\n",
    "        is_flipped = False\n",
    "        \n",
    "        if acc_raw < 0.5:\n",
    "            print(f\"\\nâš ï¸ Detected Label Reversal! (Raw Accuracy: {acc_raw:.2%})\")\n",
    "            print(\">>> The model successfully clustered the data but swapped the label meanings.\")\n",
    "            print(\">>> Auto-correcting predictions (0 -> 1, 1 -> 0)...\")\n",
    "            \n",
    "            # æ‰§è¡Œåè½¬\n",
    "            final_y_pred = [1 - y for y in y_pred_raw]\n",
    "            is_flipped = True\n",
    "            \n",
    "            # é‡æ–°è®¡ç®—å‡†ç¡®ç‡\n",
    "            acc_final = accuracy_score(y_true, final_y_pred)\n",
    "        else:\n",
    "            print(f\"\\nLabel Alignment looks correct. (Raw Accuracy: {acc_raw:.2%})\")\n",
    "            acc_final = acc_raw\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 4. è¾“å‡ºè¯¦ç»†æŠ¥å‘Š\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(f\"ğŸ† FINAL ACCURACY: {acc_final:.2%}\")\n",
    "        print(\"=\"*30 + \"\\n\")\n",
    "        \n",
    "        target_names = [\"Insoluble (0)\", \"Soluble (1)\"]\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_true, final_y_pred, target_names=target_names))\n",
    "        \n",
    "        print(\"Confusion Matrix:\")\n",
    "        cm = confusion_matrix(y_true, final_y_pred)\n",
    "        print(cm)\n",
    "        \n",
    "        # å¯è§†åŒ–æ··æ·†çŸ©é˜µè§£é‡Š\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(f\"\\n[Matrix Interpretation]\")\n",
    "        print(f\"True Insoluble (Correct): {tn}\")\n",
    "        print(f\"True Soluble   (Correct): {tp}\")\n",
    "        print(f\"False Positives (Noise classified as Signal): {fp}\")\n",
    "        print(f\"False Negatives (Signal classified as Noise): {fn}\")\n",
    "\n",
    "    else:\n",
    "        print(\"âŒ Error: No matching IDs found between Prompt and Response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2348c0-b4d8-4268-94df-3d6936bbd335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
