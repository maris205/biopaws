{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f050d46f-b696-4175-b337-9e20363d780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # 设置环境变量\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# # 打印环境变量以确认设置成功\n",
    "# print(os.environ.get('HF_ENDPOINT'))\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572acc50-6138-4c50-aa11-85c949a34a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, set_seed\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af862809-f2df-4a8f-be23-741ad5ceb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lang = \"en\"\n",
    "# 设置随机种子\n",
    "set_seed(seed)\n",
    "\n",
    "result = {}\n",
    "result[\"seed\"] = seed\n",
    "result[\"type\"] = \"no_finetune_baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e80cc-9157-4b43-aaa1-f2e4691c0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型和分词器\n",
    "model_checkpoint = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 加载模型 (预训练权重 + 随机分类头)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# 移动到 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7dd096-85aa-401d-b59b-fb52e0165508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个专用的分词函数\n",
    "def tokenize_short_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"sentence1\"],\n",
    "        example[\"sentence2\"],\n",
    "        truncation=True,\n",
    "        max_length=256,      # short 子集：完全无截断\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "def tokenize_full_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"sentence1\"],\n",
    "        example[\"sentence2\"],\n",
    "        truncation=True,\n",
    "        max_length=512,      # full 子集：覆盖 ~97%，最佳平衡\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "def plot_and_save_confusion_matrix(preds, labels, dataset_name=\"Protein Short\"):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵，并打印分类报告\n",
    "    \"\"\"\n",
    "    # 1. 计算准确率\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    print(f\"[{dataset_name}] Raw Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # 2. 检查翻转\n",
    "    is_flipped = False\n",
    "    if acc < 0.5:\n",
    "        print(f\">>> Detected Label Inversion (Acc < 0.5). Rectifying...\")\n",
    "        preds = 1 - preds\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        print(f\"[{dataset_name}] Rectified Accuracy: {acc:.4f}\")\n",
    "        is_flipped = True\n",
    "    \n",
    "    # ================= [新增] 打印详细分类报告 =================\n",
    "    print(f\"\\n>>> Classification Report for {dataset_name}:\")\n",
    "    # target_names 对应 0 和 1 的含义\n",
    "    report = classification_report(labels, preds, target_names=['Non-Homologous', 'Homologous'], digits=4)\n",
    "    print(report)\n",
    "    print(\"=\"*40)\n",
    "    # ========================================================\n",
    "\n",
    "    # 3. 计算混淆矩阵\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    \n",
    "    # 4. 绘图\n",
    "    sns.set_theme(style=\"white\", font_scale=1.2)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    \n",
    "    class_names = ['Non-Homologous', 'Homologous']\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        cbar=False, \n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        linewidths=1.5,\n",
    "        linecolor='black',\n",
    "        square=True\n",
    "    )\n",
    "    \n",
    "    plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.title(f'Confusion Matrix: Protein Homology Detection\\nAccuracy: {acc:.2%}', \n",
    "              fontsize=14, pad=15, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"confusion_matrix_{dataset_name.replace(' ', '_')}_seed{seed}.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    print(f\">>> Confusion Matrix saved to: {filename}\")\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# 定义推理函数\n",
    "def run_inference(test_dataset, batch_size=64):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    # disable=True 禁用进度条以保持输出纯净\n",
    "    for i in tqdm(range(0, len(test_dataset), batch_size), desc=\"Predicting\", disable=True):\n",
    "        batch = test_dataset[i : i + batch_size]\n",
    "        \n",
    "        inputs = {\n",
    "            \"input_ids\": torch.tensor(batch[\"input_ids\"]).to(device),\n",
    "            \"attention_mask\": torch.tensor(batch[\"attention_mask\"]).to(device),\n",
    "        }\n",
    "        batch_labels = batch[\"label\"] \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            batch_preds = torch.argmax(outputs.logits, axis=-1).cpu().numpy() \n",
    "\n",
    "        preds.extend(batch_preds)\n",
    "        labels.extend(batch_labels)\n",
    "        \n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    plot_and_save_confusion_matrix(preds, labels)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75bb781-321f-4642-ae1e-e7a0d4c7406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 测试集 1: protein_pair_short\n",
    "# ==========================================\n",
    "raw_datasets_short = load_dataset('dnagpt/biopaws', 'protein_pair_short')['train'].train_test_split(test_size=0.3, seed=seed)\n",
    "\n",
    "# 直接分词\n",
    "tokenized_raw_datasets_short = raw_datasets_short.map(tokenize_short_function, batched=True, num_proc=4)\n",
    "ret_1 = run_inference(tokenized_raw_datasets_short[\"test\"])\n",
    "result[\"protein_pair_short\"] = ret_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ce39e-12b3-440a-9c86-b6213a431079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 测试集 2: protein_pair_full (\n",
    "# ==========================================\n",
    "raw_datasets_full = load_dataset('dnagpt/biopaws', 'protein_pair_full')['train'].train_test_split(test_size=0.3, seed=seed)\n",
    "\n",
    "# 直接分词 (去除了 flip_labels 以保持与基线脚本一致)\n",
    "tokenized_raw_datasets_full = raw_datasets_full.map(tokenize_full_function, batched=True, num_proc=4)\n",
    "ret_2 = run_inference(tokenized_raw_datasets_full[\"test\"])\n",
    "result[\"protein_pair_full\"] = ret_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c63c8-d06f-4426-9476-458a48ee5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 输出结果\n",
    "# ==========================================\n",
    "print(json.dumps(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59826e1a-722c-4690-a343-927e6dbfebfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d00a8-d15e-4d24-81a7-22ad564eeaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
