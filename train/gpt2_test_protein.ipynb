{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcaea864-b707-4651-965d-b8eefa1b0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # 设置环境变量\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# # 打印环境变量以确认设置成功\n",
    "# print(os.environ.get('HF_ENDPOINT'))\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cc9d73-f0cb-4392-8280-782275dc7036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 15:53:13.358209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-26 15:53:13.373769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-26 15:53:13.378501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-26 15:53:13.389950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-26 15:53:14.291423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import json\n",
    "from transformers import set_seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8255851b-d2c4-437c-a306-fcb00ccab684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Test (No Training) with Seed: 7967\n"
     ]
    }
   ],
   "source": [
    "# 2. 设置随机种子\n",
    "# 这对于\"无微调\"模型尤为重要，因为分类头(Classification Head)是随机初始化的\n",
    "# 不同的种子会导致完全不同的随机猜测结果\n",
    "\n",
    "# 动态生成随机种子\n",
    "import random\n",
    "#seed = random.randint(0, 10000)\n",
    "seed = 7967\n",
    "set_seed(seed)\n",
    "\n",
    "result = {}\n",
    "result[\"seed\"] = seed\n",
    "result[\"type\"] = \"no_finetune_baseline\" # 标记这是无微调的基线测试\n",
    "\n",
    "print(f\"Running Baseline Test (No Training) with Seed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a744bd7-b674-4048-b303-d4f85bdd694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 初始化模型和分词器\n",
    "model_checkpoint = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 加载模型：注意，这里加载的是预训练的 Transformer + 随机初始化的分类头\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# 确保模型在 GPU 上\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval() # 直接进入评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d3081f-1df2-45fa-a3f6-1516c19d7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义分词函数\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"sentence1\"], \n",
    "        example[\"sentence2\"], \n",
    "        truncation=True,\n",
    "        max_length=256, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "# 定义推理函数 (封装以复用)\n",
    "def run_inference(test_dataset, batch_size=64):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(test_dataset), batch_size), desc=\"Predicting\"):\n",
    "        batch = test_dataset[i : i + batch_size]\n",
    "        \n",
    "        # 转换为 Tensor 并移动到 GPU\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.tensor(batch[\"input_ids\"]).to(device),\n",
    "            \"attention_mask\": torch.tensor(batch[\"attention_mask\"]).to(device),\n",
    "        }\n",
    "        batch_labels = batch[\"label\"] \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # 取最大概率的类别\n",
    "            batch_preds = torch.argmax(outputs.logits, axis=-1).cpu().numpy() \n",
    "\n",
    "        preds.extend(batch_preds)\n",
    "        labels.extend(batch_labels)\n",
    "        \n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f4ea9e-dbac-405e-8875-aea569c708cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Test Dataset 1: protein_sim_pair_450bp...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfac5b5f9af4014b99621689a68d1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46266c50e3254ff59e5a10915b09eaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558ca7a7ad2f41eb8485305de0c5d0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/16200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e344912bcbeb4df18a0e4e52c4811b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 29/29 [00:04<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1: {'accuracy': 0.55, 'f1': 0.14915966386554622}\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 测试集 1: protein_sim_pair_450bp (全长/较长序列)\n",
    "# ==========================================\n",
    "print(\"Loading Test Dataset 1: protein_sim_pair_450bp...\")\n",
    "raw_datasets_1 = load_dataset('dnagpt/gene_lan_transfer', 'protein_sim_pair_450bp')['train'].train_test_split(test_size=0.1, seed=seed)\n",
    "    \n",
    "# 你的原始逻辑中，这个数据集似乎不需要翻转标签，只是为了过一下 map 流程\n",
    "# 保持原样以确保数据一致性\n",
    "def process_data_1(example):\n",
    "    return example\n",
    "\n",
    "processed_datasets_1 = raw_datasets_1.map(process_data_1, batched=False)\n",
    "tokenized_datasets_1 = processed_datasets_1.map(tokenize_function, batched=True, num_proc=4)\n",
    "\n",
    "# 运行推理\n",
    "ret_1 = run_inference(tokenized_datasets_1[\"test\"])\n",
    "result[\"dna_protein_pair_full\"] = ret_1\n",
    "print(f\"Result 1: {ret_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adacc2bb-bda6-4e9f-92fb-54d64c324147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Test Dataset 2: protein_sim_pair_150bp...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f070d6fa524edba771928b269a799f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cf35196c5847848dfba7ee320b178c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375ad001eafa4f948fbfc897465e8e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b02f6fd7a414a2fa825c4aaecac7ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 141/141 [00:19<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 2: {'accuracy': 0.5484444444444444, 'f1': 0.16378600823045267}\n",
      "{\"seed\": 7967, \"type\": \"no_finetune_baseline\", \"dna_protein_pair_full\": {\"accuracy\": 0.55, \"f1\": 0.14915966386554622}, \"protein_pair_50\": {\"accuracy\": 0.5484444444444444, \"f1\": 0.16378600823045267}}\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 测试集 2: protein_sim_pair_150bp (较短/随机翻转)\n",
    "# ==========================================\n",
    "\n",
    "raw_datasets_2 = load_dataset('dnagpt/gene_lan_transfer', 'protein_sim_pair_150bp')['train'].train_test_split(test_size=0.5, seed=seed)\n",
    "\n",
    "# 你的原始逻辑中，这里进行了标签翻转 (label = 1 - label)\n",
    "def flip_labels(example):\n",
    "    return example\n",
    "\n",
    "flipped_datasets_2 = raw_datasets_2.map(flip_labels, batched=False)\n",
    "tokenized_datasets_2 = flipped_datasets_2.map(tokenize_function, batched=True, num_proc=4)\n",
    "\n",
    "# 运行推理\n",
    "ret_2 = run_inference(tokenized_datasets_2[\"test\"])\n",
    "result[\"protein_pair_50\"] = ret_2\n",
    "print(f\"Result 2: {ret_2}\")\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 输出结果\n",
    "# ==========================================\n",
    "print(json.dumps(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15feb59b-73c1-462d-b9ed-ceb607a38f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051323aa-01bf-4487-a571-2aad343bc6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
